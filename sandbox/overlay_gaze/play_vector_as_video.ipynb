{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2784bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023 Gabriel J. Diaz @ RIT\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "# %pylab inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "\n",
    "from pathlib import Path, PurePath\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from flow_source import *\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93954748",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [640/50., 480 /50.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a0d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(bgr_image,win_size):\n",
    "    \n",
    "    # crops off the bad OF estimation from the outer parts of the image\n",
    "    h = np.shape(bgr_image)[0]\n",
    "    w = np.shape(bgr_image)[1]\n",
    "\n",
    "    # width of analysis window in proportions of image width/height\n",
    "\n",
    "    b = int(h/2 + (win_size*h)/2)\n",
    "    t = int(h/2 - (win_size*h)/2)\n",
    "    l = int(w/2 - (win_size*w)/2)\n",
    "    r = int(w/2 + (win_size*w)/2)\n",
    "\n",
    "    sm_image = bgr_image[t:b,l:r,:]\n",
    "\n",
    "    return sm_image\n",
    "\n",
    "    \n",
    "def bgr_flow_frame_to_vector_flow(bgr_frame):\n",
    "    \n",
    "    hsv = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    mag = hsv[...,2]\n",
    "    angle = (hsv[..., 0] * np.pi * 2.0) / 180.0 # angles are in radians here\n",
    "    \n",
    "    u = np.cos(angle) * mag * -1 # this is the same as flow[...,0] * mag * -1, as I did above\n",
    "    v = np.sin(angle) * mag\n",
    "    \n",
    "#     mag = np.array(mag).astype(np.float64)\n",
    "#     angle = np.array(angle).astype(np.float64)    \n",
    "#     u, v = cv2.polarToCart(mag, angle, angleInDegrees = True)\n",
    "    \n",
    "     \n",
    "    flow = np.zeros([np.shape(bgr_frame)[0],np.shape(bgr_frame)[1],2])\n",
    "\n",
    "    flow[...,0] = u\n",
    "    flow[...,1] = v\n",
    "    \n",
    "    return flow\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997e5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_flow_overlay(image_in, flow_in, crop_to=0.8, skippts=5,scale=20, scale_units = 'width',width=.008, return_image = False):\n",
    "    \n",
    "    dpi = 100\n",
    "    fig, ax = plt.subplots()\n",
    "    #plt.subplots(figsize=(np.shape(image_in)[1] / dpi, np.shape(image_in)[0] / dpi))\n",
    "    canvas = FigureCanvas(fig)\n",
    "    ax.margins(0)\n",
    "\n",
    "    if crop_to:\n",
    "        image_in = crop_image(image_in,crop_to)\n",
    "        flow_in = crop_image(flow_in,crop_to)\n",
    "    \n",
    "    s = slice(None,None,skippts)\n",
    "    \n",
    "    xmax=np.shape(image_in)[1]\n",
    "    xpoints = int(np.shape(image_in)[1])\n",
    "    x=np.linspace(0,np.shape(image_in)[1],xmax)\n",
    "\n",
    "    ymax=np.shape(image_in)[0]\n",
    "    ypoints = int(np.shape(image_in)[0])\n",
    "    y=np.linspace(0,np.shape(image_in)[0],ymax)\n",
    "\n",
    "    x = x[s]\n",
    "    y = y[s]\n",
    "    x2d,y2d=np.meshgrid(x,y,indexing='xy')\n",
    "\n",
    "    u = flow_in[...,0]\n",
    "    v = flow_in[...,1]\n",
    "    \n",
    "    u = (u[s,s]/255) * scale\n",
    "    v = (v[s,s]/255) * scale\n",
    "\n",
    "    mag = np.sqrt(u**2 + v**2)\n",
    "    xs, ys = np.where( mag > 1)\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(image_in, cv2.COLOR_BGR2RGB))\n",
    "    ax.axis('off') \n",
    "    \n",
    "    plt.quiver(x2d[xs,ys],y2d[xs,ys],u[xs,ys],v[xs,ys],color='white', alpha=0.7, width=width,scale = scale,\n",
    "                  scale_units = 'inches')\n",
    "    \n",
    "#     if skippts:\n",
    "#         skip=(slice(None,None,skippts),slice(None,None,skippts)) #don't plot all the point as this get too messy\n",
    "#         plt.quiver(x2d[skip], y2d[skip],u[skip],v[skip],color='white', alpha=0.7, width=width,scale = scale,\n",
    "#                   scale_units = 'inches')\n",
    "#     else:\n",
    "#         plt.quiver(x2d,y2d, u, v, color='white',alpha=0.5)\n",
    "    \n",
    "    if return_image:\n",
    "        \n",
    "        canvas.draw()  # draw the canvas, cache the renderer\n",
    "        image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "        image_from_plot = image_from_plot.reshape(fig.canvas.get_width_height()[::-1] + (3,)) \n",
    "        return image_from_plot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c8c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def visualize_flow_as_vectors(frame, flow, divisor=15, crop_to = 1.0,thickness = 2, tipLength = 0.35, scale = 1):\n",
    "\n",
    "        '''Display image with a visualisation of a flow over the top.\n",
    "        A divisor controls the density of the quiver plot.'''\n",
    "\n",
    "        # create a blank mask, on which lines will be drawn.\n",
    "        mask = np.zeros([np.shape(frame)[0], np.shape(frame)[1], 3], np.uint8)\n",
    "        \n",
    "        if crop_to:\n",
    "            frame = crop_image(frame,crop_to)\n",
    "            flow = crop_image(flow,crop_to)\n",
    "        \n",
    "        u = flow[...,0] # height\n",
    "        v = -flow[...,1] # width\n",
    "    \n",
    "        for r in range(0, int(np.shape(flow)[0] / divisor)): # iterate through height\n",
    "            for c in range(0, int(np.shape(flow)[1] / divisor)): # iterate through width\n",
    "                \n",
    "                origin_x = c * divisor\n",
    "                origin_y = r * divisor\n",
    "\n",
    "                endpoint_x = origin_x + int(u[origin_y, origin_x] * scale)\n",
    "                endpoint_y = origin_y + int(v[origin_y, origin_x] * scale)\n",
    "\n",
    "                mask = cv2.arrowedLine(mask, (origin_x, origin_y), (endpoint_x, endpoint_y), color=(255, 255, 255 ), \n",
    "                                       thickness = thickness, tipLength = tipLength)\n",
    "\n",
    "        return cv2.addWeighted(frame, 0.5, mask, 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "567e96ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n"
     ]
    }
   ],
   "source": [
    "#hsv_video_path = r'D:\\Data\\Driving_1\\Aware-AI\\CM\\S001\\PupilData\\000\\exports\\000\\world_nvidia2_gaze-centered_hsv.mp4'\n",
    "hsv_video_path = r'D:\\Data\\Driving_1\\Aware-AI\\CM\\S001\\PupilData\\000\\exports\\000\\world_nvidia2_hsv_overlay.mp4'\n",
    "\n",
    "#hsv_video_path =  r'D:\\Github\\retinal_flow_toolkit\\flow_out\\linear_travel\\linear_travel_nvidia2_hsv_overlay.mp4'\n",
    "\n",
    "hsv_video = cv2.VideoCapture(hsv_video_path)\n",
    "\n",
    "# number of frames in the video\n",
    "length = int(hsv_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print( length )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5be103c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14428\n"
     ]
    }
   ],
   "source": [
    "world_video_path = r'D:\\Data\\Driving_1\\Aware-AI\\CM\\S001\\PupilData\\000\\world.mp4'\n",
    "#world_video_path = r'D:\\Github\\retinal_flow_toolkit\\demo_input_video\\linear_travel.mp4'\n",
    "\n",
    "world_video = cv2.VideoCapture(world_video_path)\n",
    "\n",
    "# number of frames in the video\n",
    "length = int(world_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print( length )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c72bb",
   "metadata": {},
   "source": [
    "## Single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44369bf8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\OpenCVGPU\\opencv-4.6.0\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36176\\362248676.py\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mhsv_video\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mflow_success\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbgr_flow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhsv_video\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mflow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbgr_flow_frame_to_vector_flow\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mbgr_flow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mplot_flow_overlay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbgr_world\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskippts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_units\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'width'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.004\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36176\\116296268.py\u001b[0m in \u001b[0;36mbgr_flow_frame_to_vector_flow\u001b[1;34m(bgr_frame)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbgr_flow_frame_to_vector_flow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbgr_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mhsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbgr_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mmag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhsv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\OpenCVGPU\\opencv-4.6.0\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "w_f = 7800-6\n",
    "f_f = 7800\n",
    "\n",
    "# w_f = 10800 -5\n",
    "# f_f = 10800\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [640/100., 480 /100.]\n",
    "\n",
    "world_video.set(cv2.CAP_PROP_POS_FRAMES, w_f)\n",
    "world_success, bgr_world = world_video.read()\n",
    "\n",
    "hsv_video.set(cv2.CAP_PROP_POS_FRAMES, f_f)\n",
    "flow_success, bgr_flow = hsv_video.read()\n",
    "flow = bgr_flow_frame_to_vector_flow( bgr_flow)\n",
    "\n",
    "plot_flow_overlay(bgr_world, flow, crop_to=0.8, skippts=10,scale=None, scale_units = 'width',width=.004)\n",
    "\n",
    "####\n",
    "hsv_video.set(cv2.CAP_PROP_POS_FRAMES, f_f)\n",
    "flow_success, bgr_flow = hsv_video.read()\n",
    "flow = bgr_flow_frame_to_vector_flow( bgr_flow)\n",
    "plot_flow_overlay(bgr_flow, flow, crop_to=0.8, skippts=10,scale=None, scale_units = 'width',width=.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_video.set(cv2.CAP_PROP_FPS,29.852)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2170c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#world_video.get(cv2.CAP_PROP_FOURCC) \n",
    "#world_video.get(cv2.CAP_PROP_POS_MSEC) # CAP_PROP_FPS \n",
    "world_video.get(cv2.CAP_PROP_FPS) # 29.852196518048217\n",
    "#world_video.get(cv2.CAP_PROP_POS_AVI_RATIO) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adca265",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_video.get(cv2.CAP_PROP_FOURCC) \n",
    "#hsv_video.get(cv2.CAP_PROP_POS_MSEC) # cv2.CAP_PROP_POS_MSEC\n",
    "#hsv_video.get(cv2.CAP_PROP_FPS) # 29.852\n",
    "#hsv_video.get(cv2.CAP_PROP_POS_AVI_RATIO) #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673c6d71",
   "metadata": {},
   "source": [
    "## Single vector overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db889a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ce3128d",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\OpenCVGPU\\opencv-4.6.0\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36176\\759861472.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mhsv_video\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mflow_success\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbgr_flow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhsv_video\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mflow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbgr_flow_frame_to_vector_flow\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mbgr_flow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# plt.imshow(cv2.cvtColor(bgr_world, cv2.COLOR_BGR2RGB))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36176\\116296268.py\u001b[0m in \u001b[0;36mbgr_flow_frame_to_vector_flow\u001b[1;34m(bgr_frame)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbgr_flow_frame_to_vector_flow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbgr_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mhsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbgr_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mmag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhsv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\OpenCVGPU\\opencv-4.6.0\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "f = 10800\n",
    "#f = 20\n",
    "\n",
    "\n",
    "world_video.set(cv2.CAP_PROP_POS_FRAMES, f)\n",
    "world_success, bgr_world = world_video.read()\n",
    "\n",
    "hsv_video.set(cv2.CAP_PROP_POS_FRAMES, f)\n",
    "flow_success, bgr_flow = hsv_video.read()\n",
    "flow = bgr_flow_frame_to_vector_flow( bgr_flow)\n",
    "# plt.imshow(cv2.cvtColor(bgr_world, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "plot_flow_overlay(bgr_world, flow, crop_to=0.8, skippts=10,scale=None, scale_units = 'width',width=.004)\n",
    "# plot_flow_overlay(bgr_world, flow, crop_to=0.8, skippts=10,scale=None, scale_units = 'width',width=.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "443e7bbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\OpenCVGPU\\opencv-4.6.0\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36176\\669117051.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mhsv_video\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mflow_success\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbgr_flow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhsv_video\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mflow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbgr_flow_frame_to_vector_flow\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mbgr_flow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# plt.imshow(cv2.cvtColor(bgr_world, cv2.COLOR_BGR2RGB))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36176\\116296268.py\u001b[0m in \u001b[0;36mbgr_flow_frame_to_vector_flow\u001b[1;34m(bgr_frame)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbgr_flow_frame_to_vector_flow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbgr_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mhsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbgr_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mmag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhsv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\OpenCVGPU\\opencv-4.6.0\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "f = 10800\n",
    "#f = 20\n",
    "\n",
    "\n",
    "world_video.set(cv2.CAP_PROP_POS_FRAMES, f)\n",
    "world_success, bgr_world = world_video.read()\n",
    "\n",
    "hsv_video.set(cv2.CAP_PROP_POS_FRAMES, f)\n",
    "flow_success, bgr_flow = hsv_video.read()\n",
    "flow = bgr_flow_frame_to_vector_flow( bgr_flow)\n",
    "# plt.imshow(cv2.cvtColor(bgr_world, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plot_flow_overlay(bgr_flow, flow, crop_to=0.8, skippts=10,scale=None, scale_units = 'width',width=.004)\n",
    "# plot_flow_overlay(bgr_world, flow, crop_to=0.8, skippts=10,scale=None, scale_units = 'width',width=.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c28cd37",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\OpenCVGPU\\opencv-4.6.0\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36176\\3607043622.py\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mhsv_video\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mflow_success\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbgr_flow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhsv_video\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mflow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbgr_flow_frame_to_vector_flow\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mbgr_flow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplot_flow_overlay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbgr_world\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskippts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_units\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'width'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.004\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36176\\116296268.py\u001b[0m in \u001b[0;36mbgr_flow_frame_to_vector_flow\u001b[1;34m(bgr_frame)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbgr_flow_frame_to_vector_flow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbgr_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mhsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbgr_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mmag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhsv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\OpenCVGPU\\opencv-4.6.0\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "f = 10840\n",
    "#f = 10\n",
    "\n",
    "world_video.set(cv2.CAP_PROP_POS_FRAMES, f)\n",
    "world_success, bgr_world = world_video.read()\n",
    "\n",
    "hsv_video.set(cv2.CAP_PROP_POS_FRAMES, f)\n",
    "flow_success, bgr_flow = hsv_video.read()\n",
    "flow = bgr_flow_frame_to_vector_flow( bgr_flow)\n",
    "\n",
    "plot_flow_overlay(bgr_world, flow, crop_to=0.8, skippts=10,scale=None, scale_units = 'width',width=.004)\n",
    "\n",
    "\n",
    "flow_im = visualize_flow_as_vectors(bgr_world, flow, \n",
    "                                    divisor=10, \n",
    "                                    crop_to = 1.0,\n",
    "                                    thickness = 2, \n",
    "                                    tipLength = 0.35,\n",
    "                                    scale = .1)\n",
    "\n",
    "flow_im = crop_image(flow_im,0.8)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(cv2.cvtColor(flow_im, cv2.COLOR_BGR2RGB))\n",
    "ax.axis('off') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a675ae76",
   "metadata": {},
   "source": [
    "## Single overlay sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3712aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c65f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 10800\n",
    "#f = 10\n",
    "\n",
    "world_video.set(cv2.CAP_PROP_POS_FRAMES, f)\n",
    "world_success, bgr_world = world_video.read()\n",
    "\n",
    "hsv_video.set(cv2.CAP_PROP_POS_FRAMES, f)\n",
    "flow_success, bgr_flow = hsv_video.read()\n",
    "flow = bgr_flow_frame_to_vector_flow( bgr_flow)\n",
    "# plt.imshow(cv2.cvtColor(bgr_world, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plot_flow_overlay(bgr_world, flow, crop_to=0.8, skippts=10,scale=None, scale_units = 'width',width=.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de3071",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = 10800\n",
    "#f = 1\n",
    "\n",
    "\n",
    "buffer_len = 10\n",
    "start_frame = f\n",
    "end_frame = start_frame + buffer_len*10\n",
    "\n",
    "world_video.set(cv2.CAP_PROP_POS_FRAMES, f)\n",
    "hsv_video.set(cv2.CAP_PROP_POS_FRAMES, f)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [640/40., 480/40.]\n",
    "\n",
    "\n",
    "flow_fr_y_x_uv = []\n",
    "\n",
    "flow_buffer = deque([] * buffer_len)\n",
    "div_time = []\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "frame_num = f\n",
    "\n",
    "world_success = True\n",
    "while world_success:\n",
    "    \n",
    "    world_success, bgr_world = world_video.read()\n",
    "    flow_success, bgr_flow = hsv_video.read()\n",
    "    \n",
    "    #if flow_success and world_success:\n",
    "    \n",
    "    flow = bgr_flow_frame_to_vector_flow( bgr_flow)\n",
    "    flow_buffer.appendleft(flow)\n",
    " \n",
    "    combined_flow = np.sum(flow_buffer,axis=0)\n",
    "    combined_flow = cv2.blur(combined_flow,[7,7])\n",
    "    \n",
    "    flow_fr_y_x_uv.append(flow)\n",
    "\n",
    "#     flow_im = plot_flow_overlay(bgr_world, \n",
    "#                                 combined_flow, \n",
    "#                                 crop_to=0.8, \n",
    "#                                 skippts=15,\n",
    "#                                 scale=10, \n",
    "#                                 scale_units = 'width',\n",
    "#                                 width=.004, \n",
    "#                                 return_image=True)\n",
    "    \n",
    "#     cv2.imshow(\"test\", cv2.cvtColor(flow_im, cv2.COLOR_BGR2RGB) )\n",
    "#     plt.close()  \n",
    "    \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "    \n",
    "#     cv2.waitKey(1000)\n",
    "    \n",
    "    \n",
    "#     if frame_num >= start_frame + buffer_len:\n",
    "#         success = False\n",
    "#     print(frame_num)\n",
    "    if frame_num >= end_frame:\n",
    "        world_success = False\n",
    "        \n",
    "    frame_num = frame_num + 1\n",
    "    \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea8f38",
   "metadata": {},
   "source": [
    "### Rescale and moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc03db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "# window_size = [10,480,640]\n",
    "# cumulativeflow_fr_y_x_uv = sliding_window_view(flow_fr_y_x_uv, window_size,axis=0).sum(axis=0)\n",
    "# np.shape(cumulativeflow_fr_y_x_uv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989a9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_flow = np.sum(flow,axis=0)\n",
    "# combined_flow = cv2.blur(combined_flow,[7,7])\n",
    "# ret = np.cumsum(a,axis=0, dtype=float)\n",
    "\n",
    "cumulativeflow_fr_y_x_uv = []\n",
    "flow_fr_y_x_uv = np.array(flow_fr_y_x_uv)\n",
    "\n",
    "win_size = 10\n",
    "\n",
    "for i in np.arange(win_size, np.shape(flow_fr_y_x_uv)[0]-win_size):\n",
    "    cumulativeflow_fr_y_x_uv.append( np.cumsum(flow_fr_y_x_uv[np.arange(i,i+win_size),...],axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58141daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulativeflow_fr_y_x_uv = []\n",
    "cumulativeflow_fr_y_x_uv.append( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08fbfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.tile(np.zeros_like(flow_fr_y_x_uv[0,:]),[1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3bb7a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def moving_sum(a, n=3):\n",
    "n = 10\n",
    "a = flow_fr_y_x_uv\n",
    "ret = np.cumsum(a,axis=0, dtype=float)\n",
    "np.shape(ret)\n",
    "\n",
    "# ret[n:] = ret[n:] - ret[:-n]\n",
    "# np.shape(ret[n - 1:])\n",
    "# return ret[n - 1:]\n",
    "\n",
    "# np.shape(flow_fr_y_x_uv)\n",
    "\n",
    "# Set saccade frames to nan\n",
    "# Integrate over non-scaccade frames\n",
    "\n",
    "# flow_fr_y_x_uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec0f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_pixel = np.divide(np.shape(bgr_world)[:2],2)\n",
    "\n",
    "center_pixel\n",
    "# np.shape(bgr_world)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_image = cv2.resize(bgr_flow, [15,11])\n",
    "tiny_flow = cv2.resize(flow_im, [15,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015572ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_flow_overlay(tiny_image,tiny_flow,crop_to=False,skippts=False)\n",
    "\n",
    "image_in = tiny_image\n",
    "flow_in = tiny_flow\n",
    "\n",
    "xmax = np.shape(image_in)[1]\n",
    "xpoints = int(np.shape(image_in)[1])\n",
    "x = np.linspace(0,np.shape(image_in)[1]-1,xmax)\n",
    "\n",
    "ymax = np.shape(image_in)[0]\n",
    "ypoints = int(np.shape(image_in)[0])\n",
    "y=np.linspace(0,np.shape(image_in)[0]-1,ymax)\n",
    "\n",
    "x2d,y2d=np.meshgrid(x,y,indexing='xy')\n",
    "\n",
    "u = flow_in[...,0]\n",
    "v = flow_in[...,1]\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_in, cv2.COLOR_BGR2RGB),origin='upper')\n",
    "plt.quiver(x2d,y2d, u, v, color='white',alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59818d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divergence_npgrad(u, v):\n",
    "    dFx_dx = np.gradient(v, axis=0)\n",
    "    dFy_dy = np.gradient(u, axis=1)\n",
    "    return dFx_dx + dFy_dy\n",
    "\n",
    "def curl_npgrad(u, v):    \n",
    "    dFx_dy = np.gradient(v, axis=1)\n",
    "    dFy_dx = np.gradient(u, axis=0)\n",
    "    curl = dFy_dx - dFx_dy\n",
    "    return curl\n",
    "\n",
    "divergence_npgrad(u,v) \n",
    "# divergence_npgrad(u,v) \n",
    "# curl_npgrad(u,v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1803cacd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
