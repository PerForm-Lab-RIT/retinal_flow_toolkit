{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023 Gabriel J. Diaz @ RIT\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import av\n",
    "import logging\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from pathlib import Path, PurePath\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "# from retinal_flow_toolkit import .flow_source\n",
    "from flow_source import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/gjdpci/Documents/GitHub/retinal_flow_toolkit/sandbox/overlay_gaze',\n",
       " '/Users/gjdpci/opt/anaconda3/envs/Pytorch_1/lib/python38.zip',\n",
       " '/Users/gjdpci/opt/anaconda3/envs/Pytorch_1/lib/python3.8',\n",
       " '/Users/gjdpci/opt/anaconda3/envs/Pytorch_1/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/Users/gjdpci/opt/anaconda3/envs/Pytorch_1/lib/python3.8/site-packages',\n",
       " '/Users/gjdpci/opt/anaconda3/envs/Pytorch_1/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/Users/gjdpci/.ipython',\n",
       " '../..',\n",
       " 'core']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# file_path = Path('D:\\\\Github\\\\retinal_flow_toolkit\\\\videos\\\\Yoyo-LVRA.mp4')\n",
    "\n",
    "a_file_path = Path(os.path.join('..','..','pupil_labs_data','cb13'))\n",
    "a_file_path\n",
    "source = pupil_labs_source(a_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = source.file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_containers_and_streams(self, algorithm, visualize_as):\n",
    "\n",
    "    container_in = av.open(self.file_path)\n",
    "    average_fps = container_in.streams.video[0].average_rate\n",
    "    height = container_in.streams.video[0].height\n",
    "    width = container_in.streams.video[0].width\n",
    "    container_in.ign_dts = True\n",
    "    container_in.sort_dts = True\n",
    "\n",
    "\n",
    "    ##############################\n",
    "    # prepare video out\n",
    "    if visualize_as == 'gaze_overlay':\n",
    "        video_out_name = self.source_file_name + '_gaze-overlay.mp4' \n",
    "    else:\n",
    "        video_out_name = self.source_file_name + '_' + algorithm + '_' + visualize_as + '.mp4'\n",
    "\n",
    "    if os.path.isdir(self.video_out_path) is False:\n",
    "        os.makedirs(self.video_out_path)\n",
    "\n",
    "    container_out = av.open(os.path.join(self.video_out_path, video_out_name), mode=\"w\", timeout=None)\n",
    "    \n",
    "    out_streams = []\n",
    "    \n",
    "    stream_out = container_out.add_stream(\"libx264\", framerate=average_fps)\n",
    "    stream_out.options[\"crf\"] = \"20\"\n",
    "    stream_out.pix_fmt = container_in.streams.video[0].pix_fmt\n",
    "    stream_out.time_base = container_in.streams.video[0].time_base\n",
    "    stream_out = self.set_stream_dimensions(stream_out, visualize_as, height, width)\n",
    "    \n",
    "    out_streams.append(stream_out)\n",
    "    if visualize_as == 'gaze_overlay':\n",
    "        overlay_stream = container_out.add_stream(\"libx264\", framerate=average_fps)\n",
    "        overlay_stream.options[\"crf\"] = \"20\"\n",
    "        overlay_stream.pix_fmt = 'yuva444p10le'\n",
    "#         overlay_stream.pix_fmt = container_in.streams.video[0].pix_fmt #'yuva444p10le'\n",
    "        overlay_stream.time_base = container_in.streams.video[0].time_base\n",
    "        overlay_stream = self.set_stream_dimensions(stream_out, visualize_as, height, width)\n",
    "        out_streams.append(overlay_stream)\n",
    "    \n",
    "    return container_in, container_out, out_streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_gaze_on_frame(self, frame_width, frame_height, frame_index):\n",
    "    \n",
    "    if not type(source.gaze_data ) == pd.DataFrame:\n",
    "        self.import_gaze_from_exports()\n",
    "        self.process_gaze_data()\n",
    "    \n",
    "    med_xy = self.get_median_gaze_for_frame(frame_index)\n",
    "\n",
    "    frame = np.zeros((frame_height,frame_width,4), np.uint8)\n",
    "    \n",
    "    if med_xy:\n",
    "\n",
    "        median_x, median_y = med_xy\n",
    "\n",
    "        height = np.shape(frame)[0]\n",
    "        width = np.shape(frame)[1]\n",
    "\n",
    "        frame = cv2.line(frame, (int(width * median_x), 0), (int(width * median_x), height),\n",
    "                         (255, 0, 0,1), thickness=2)\n",
    "\n",
    "        frame = cv2.line(frame, (0, int(height * median_y)), (width, int(height * median_y)),\n",
    "                         (255, 0, 0,1), thickness=2)\n",
    "\n",
    "        cv2.imwrite('temp.png', frame, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_gaze_from_exports(self):\n",
    "    gaze_positions_path = os.path.join(self.export_folder, 'gaze_positions.csv')\n",
    "\n",
    "    if os.path.exists(gaze_positions_path) is False:\n",
    "        logger.error('No gaze_positions found in the exports folder.')\n",
    "\n",
    "    # Defaults to the most recent pupil export folder (highest number)\n",
    "    self.gaze_data = pd.read_csv(gaze_positions_path)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def overlay_gaze_on_video(self):\n",
    "    \n",
    "    container_in, container_out, out_streams = self.create_containers_and_streams(algorithm=False, \n",
    "                                                                                visualize_as='gaze_overlay')\n",
    "    \n",
    "    stream_in = container_in.streams.video[0]\n",
    "    \n",
    "    num_frames = stream_in.frames\n",
    "    \n",
    "    # for raw_frame in container_in.decode(video=0):\n",
    "    for raw_frame in tqdm(container_in.decode(video=0), desc=\"Working.\", unit= 'frames',total = num_frames):\n",
    "        \n",
    "        current_bgr = raw_frame.to_ndarray(format='bgr24')\n",
    "        current_bgr_processed = self.preprocess_frame(current_bgr)\n",
    "        \n",
    "        overlay_frame = self.draw_gaze_overlay(raw_frame.width, raw_frame.height, raw_frame.index)\n",
    "    \n",
    "        self.encode_frame(container_out, out_streams[1], overlay_frame, raw_frame, stream_in)\n",
    "        self.encode_frame(container_out, out_streams[0], current_bgr_processed, raw_frame, stream_in)\n",
    "        \n",
    "    \n",
    "    self.encode_frame(container_out, out_streams[0], current_bgr_processed, raw_frame, stream_in,flush=True)\n",
    "    self.encode_frame(container_out, out_streams[1], overlay_frame, raw_frame, stream_in, flush=True)\n",
    "\n",
    "    container_out.close()\n",
    "    container_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_frame(self, c_out, s_out, image_out, rawframe_in, s_in, flush = False):\n",
    "\n",
    "    if np.shape(image_out)[2] == 3:\n",
    "        frame_out = av.VideoFrame.from_ndarray(image_out, format='bgr24')\n",
    "    else:\n",
    "        frame_out = av.VideoFrame.from_ndarray(image_out, format='bgra')\n",
    "\n",
    "    frame_out.time_base = rawframe_in.time_base\n",
    "    frame_out.pts = rawframe_in.pts\n",
    "\n",
    "    if flush:\n",
    "        for packet_out in s_out.encode():\n",
    "            c_out.mux(packet_out)\n",
    "    else:\n",
    "\n",
    "        for packet_out in s_out.encode(frame_out):\n",
    "            packet_out.stream = s_out\n",
    "            packet_out.time_base = s_in.time_base\n",
    "            packet_out.pts = rawframe_in.pts\n",
    "            c_out.mux(packet_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "\n",
    "source.overlay_gaze_on_video = types.MethodType( overlay_gaze_on_video, source )\n",
    "\n",
    "source.draw_gaze_overlay = types.MethodType( draw_gaze_overlay, source )\n",
    "\n",
    "source.create_containers_and_streams = types.MethodType( create_containers_and_streams, source )\n",
    "\n",
    "source.import_gaze_from_exports = types.MethodType( import_gaze_from_exports, source )\n",
    "\n",
    "source.encode_frame = types.MethodType( encode_frame, source )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Working.:   0%|                                   | 0/92882 [00:04<?, ?frames/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gy/wzd471c14k762xp4b_xt87xr0000gq/T/ipykernel_25724/1166252396.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverlay_gaze_on_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/gy/wzd471c14k762xp4b_xt87xr0000gq/T/ipykernel_25724/4072452755.py\u001b[0m in \u001b[0;36moverlay_gaze_on_video\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcurrent_bgr_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_bgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moverlay_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_gaze_overlay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_streams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlay_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gy/wzd471c14k762xp4b_xt87xr0000gq/T/ipykernel_25724/3618897073.py\u001b[0m in \u001b[0;36mdraw_gaze_overlay\u001b[0;34m(self, frame_width, frame_height, frame_index)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaze_data\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_gaze_from_exports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_gaze_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmed_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_median_gaze_for_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/retinal_flow_toolkit/sandbox/overlay_gaze/../../flow_source.py\u001b[0m in \u001b[0;36mprocess_gaze_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0midx_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaze_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         \u001b[0mmed_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_median_gaze_for_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mmed_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmed_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/retinal_flow_toolkit/sandbox/overlay_gaze/../../flow_source.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0midx_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaze_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         \u001b[0mmed_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_median_gaze_for_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mmed_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmed_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/retinal_flow_toolkit/sandbox/overlay_gaze/../../flow_source.py\u001b[0m in \u001b[0;36mget_median_gaze_for_frame\u001b[0;34m(self, frame_index)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_median_gaze_for_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mgaze_samples_on_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaze_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaze_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'world_index'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mframe_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         gaze_samples_on_frame = gaze_samples_on_frame[\n\u001b[1;32m    677\u001b[0m             gaze_samples_on_frame['confidence'] > self.analysis_parameters['pl_confidence_threshold']]\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Pytorch_1/lib/python3.8/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Pytorch_1/lib/python3.8/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Pytorch_1/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5622\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5623\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5625\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Pytorch_1/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Pytorch_1/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_cmp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Pytorch_1/lib/python3.8/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;31m# error: \"None\" not callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Pytorch_1/lib/python3.8/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_TEST_MODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "source.overlay_gaze_on_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b = source.create_containers_and_streams(False, 'gaze_overlay'\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_containers_and_streams(self, algorithm, visualize_as):\n",
    "\n",
    "algorithm = False\n",
    "visualize_as = 'gaze_overlay'\n",
    "\n",
    "container_in = av.open(source.file_path)\n",
    "average_fps = container_in.streams.video[0].average_rate\n",
    "height = container_in.streams.video[0].height\n",
    "width = container_in.streams.video[0].width\n",
    "\n",
    "##############################\n",
    "# prepare video out\n",
    "if visualize_as == 'gaze_overlay':\n",
    "    video_out_name = source.source_file_name + '_gaze-overlay.mp4' \n",
    "else:\n",
    "    video_out_name = source.source_file_name + '_' + algorithm + '_' + visualize_as + '.mp4'\n",
    "\n",
    "if os.path.isdir(source.video_out_path) is False:\n",
    "    os.makedirs(source.video_out_path)\n",
    "\n",
    "container_out = av.open(os.path.join(source.video_out_path, video_out_name), mode=\"w\", timeout=None)\n",
    "\n",
    "stream_out = container_out.add_stream(\"libx264\", framerate=average_fps)\n",
    "stream_out.options[\"crf\"] = \"20\"\n",
    "stream_out.pix_fmt = container_in.streams.video[0].pix_fmt\n",
    "stream_out.time_base = container_in.streams.video[0].time_base\n",
    "stream_out = source.set_stream_dimensions(stream_out, visualize_as, height, width)\n",
    "\n",
    "if visualize_as == 'gaze_overlay':\n",
    "    overlay_stream = container_out.add_stream(\"libx264\", framerate=average_fps)\n",
    "    overlay_stream.options[\"crf\"] = \"20\"\n",
    "    overlay_stream.pix_fmt = container_in.streams.video[0].pix_fmt #'yuva444p10le'\n",
    "    overlay_stream.time_base = container_in.streams.video[0].time_base\n",
    "    overlay_stream = source.set_stream_dimensions(stream_out, visualize_as, height, width)\n",
    "\n",
    "print(f'Streams: {len(container_out.streams)}')\n",
    "# return container_in, container_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# container_in, container_out = self.create_containers_and_streams(algorithm=False,visualize_as='gaze_overlay')\n",
    "self = source\n",
    "\n",
    "stream_in = container_in.streams.video[0]\n",
    "\n",
    "num_frames = stream_in.frames\n",
    "\n",
    "# for raw_frame in container_in.decode(video=0):\n",
    "for raw_frame in tqdm(container_in.decode(video=0), desc=\"Working.\", unit= 'frames',total = num_frames):\n",
    "\n",
    "    current_bgr = raw_frame.to_ndarray(format='bgr24')\n",
    "    current_bgr_processed = self.preprocess_frame(current_bgr)\n",
    "\n",
    "    overlay_frame = self.draw_gaze_overlay(raw_frame.width, raw_frame.height, raw_frame.index)\n",
    "\n",
    "    self.encode_frame(container_out, stream_out, current_bgr_processed, raw_frame, stream_in)\n",
    "    self.encode_frame(container_out, overlay_stream, overlay_frame, raw_frame, stream_in)\n",
    "\n",
    "self.encode_frame(container_out, stream_out, current_bgr_processed, raw_frame, stream_in)\n",
    "self.encode_frame(container_out, overlay_stream, overlay_frame, raw_frame, stream_in)\n",
    "\n",
    "container_out.close()\n",
    "container_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = np.zeros((480,640,4), np.uint8)\n",
    "np.shape(frame)[2] == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
