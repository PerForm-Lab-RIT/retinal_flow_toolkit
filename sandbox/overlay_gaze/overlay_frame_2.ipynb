{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023 Gabriel J. Diaz @ RIT\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import av\n",
    "import logging\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from pathlib import Path, PurePath\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "# from retinal_flow_toolkit import .flow_source\n",
    "from flow_source import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Github\\\\retinal_flow_toolkit\\\\sandbox\\\\overlay_gaze',\n",
       " 'C:\\\\Users\\\\gabri\\\\anaconda3\\\\envs\\\\py38\\\\python38.zip',\n",
       " 'C:\\\\Users\\\\gabri\\\\anaconda3\\\\envs\\\\py38\\\\DLLs',\n",
       " 'C:\\\\Users\\\\gabri\\\\anaconda3\\\\envs\\\\py38\\\\lib',\n",
       " 'C:\\\\Users\\\\gabri\\\\anaconda3\\\\envs\\\\py38',\n",
       " '',\n",
       " 'C:\\\\Users\\\\gabri\\\\anaconda3\\\\envs\\\\py38\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\gabri\\\\anaconda3\\\\envs\\\\py38\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\gabri\\\\anaconda3\\\\envs\\\\py38\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\gabri\\\\anaconda3\\\\envs\\\\py38\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\gabri\\\\anaconda3\\\\envs\\\\py38\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\gabri\\\\.ipython',\n",
       " '../..',\n",
       " 'core']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# file_path = Path('D:\\\\Github\\\\retinal_flow_toolkit\\\\videos\\\\Yoyo-LVRA.mp4')\n",
    "\n",
    "a_file_path = Path(os.path.join('..','..','pupil_labs_data','GD-Short-Driving-Video'))\n",
    "# a_file_path = Path(os.path.join('..','..','pupil_labs_data','cb13'))\n",
    "a_file_path\n",
    "source = pupil_labs_source(a_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = source.file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_containers_and_streams(self, algorithm, visualize_as):\n",
    "\n",
    "    container_in = av.open(self.file_path)\n",
    "    average_fps = container_in.streams.video[0].average_rate\n",
    "    height = container_in.streams.video[0].height\n",
    "    width = container_in.streams.video[0].width\n",
    "    # container_in.ign_dts = True\n",
    "    container_in.sort_dts = True\n",
    "\n",
    "\n",
    "    ##############################\n",
    "    # prepare video out\n",
    "    if visualize_as == 'gaze_overlay':\n",
    "        video_out_name = self.source_file_name + '_gaze-overlay.mp4' \n",
    "    else:\n",
    "        video_out_name = self.source_file_name + '_' + algorithm + '_' + visualize_as + '.mp4'\n",
    "\n",
    "    if os.path.isdir(self.video_out_path) is False:\n",
    "        os.makedirs(self.video_out_path)\n",
    "\n",
    "    container_out = av.open(os.path.join(self.video_out_path, video_out_name), mode=\"w\", timeout=None)\n",
    "    \n",
    "    out_streams = []\n",
    "    \n",
    "    stream_out = container_out.add_stream(\"libx264\", framerate=average_fps)\n",
    "    stream_out.options[\"crf\"] = \"10\"\n",
    "    stream_out.pix_fmt = container_in.streams.video[0].pix_fmt\n",
    "    stream_out.time_base = container_in.streams.video[0].time_base\n",
    "    stream_out = self.set_stream_dimensions(stream_out, visualize_as, height, width)\n",
    "    stream_out.codec_context.bit_rate = container_in.streams.video[0].codec_context.bit_rate\n",
    "    out_streams.append(stream_out)\n",
    "    \n",
    "#     if visualize_as == 'gaze_overlay':\n",
    "#         overlay_stream = container_out.add_stream(\"libx264\", framerate=average_fps)\n",
    "#         overlay_stream.options[\"crf\"] = \"20\"\n",
    "#         overlay_stream.pix_fmt = 'yuva444p10le'\n",
    "# #         overlay_stream.pix_fmt = container_in.streams.video[0].pix_fmt #'yuva444p10le'\n",
    "#         overlay_stream.time_base = container_in.streams.video[0].time_base\n",
    "#         overlay_stream = self.set_stream_dimensions(stream_out, visualize_as, height, width)\n",
    "#         out_streams.append(overlay_stream)\n",
    "    \n",
    "    \n",
    "    return container_in, container_out, out_streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_gaze_on_frame(self, frame_in, frame_index):\n",
    "    \n",
    "    if not type(source.gaze_data ) == pd.DataFrame:\n",
    "        self.import_gaze_from_exports()\n",
    "        self.process_gaze_data()\n",
    "    \n",
    "    med_xy = self.get_median_gaze_for_frame(frame_index)\n",
    "\n",
    "#     frame = np.zeros((frame_height,frame_width,4), np.uint8)\n",
    "    \n",
    "    if med_xy:\n",
    "\n",
    "        median_x, median_y = med_xy\n",
    "\n",
    "        height = np.shape(frame_in)[0]\n",
    "        width = np.shape(frame_in)[1]\n",
    "\n",
    "        frame = cv2.line(frame_in, (int(width * median_x), 0), (int(width * median_x), height),\n",
    "                         (255, 0, 0,1), thickness=2)\n",
    "\n",
    "        frame = cv2.line(frame_in, (0, int(height * median_y)), (width, int(height * median_y)),\n",
    "                         (255, 0, 0,1), thickness=2)\n",
    "\n",
    "#         cv2.imwrite('temp.png', frame_in, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "    return frame_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_gaze_from_exports(self):\n",
    "    gaze_positions_path = os.path.join(self.export_folder, 'gaze_positions.csv')\n",
    "\n",
    "    if os.path.exists(gaze_positions_path) is False:\n",
    "        logger.error('No gaze_positions found in the exports folder.')\n",
    "\n",
    "    # Defaults to the most recent pupil export folder (highest number)\n",
    "    self.gaze_data = pd.read_csv(gaze_positions_path)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def overlay_gaze_on_video(self):\n",
    "    \n",
    "    container_in, container_out, out_streams = self.create_containers_and_streams(algorithm=False, \n",
    "                                                                                visualize_as='gaze_overlay')\n",
    "    \n",
    "    stream_in = container_in.streams.video[0]\n",
    "    \n",
    "    num_frames = stream_in.frames\n",
    "    \n",
    "    # for raw_frame in container_in.decode(video=0):\n",
    "    for raw_frame in tqdm(container_in.decode(video=0), desc=\"Working.\", unit= 'frames',total = num_frames):\n",
    "        \n",
    "        current_bgr = raw_frame.to_ndarray(format='bgr24')\n",
    "        current_bgr_processed = self.preprocess_frame(current_bgr)\n",
    "        \n",
    "        overlay_frame = self.overlay_gaze_on_frame(current_bgr_processed, raw_frame.index)\n",
    "    \n",
    "        self.encode_frame(container_out, out_streams[0], current_bgr_processed, raw_frame, stream_in)\n",
    "#         self.encode_frame(container_out, out_streams[1], overlay_frame, raw_frame, stream_in)\n",
    "        \n",
    "    \n",
    "    self.encode_frame(container_out, out_streams[0], current_bgr_processed, raw_frame, stream_in,flush=True)\n",
    "#     self.encode_frame(container_out, out_streams[1], overlay_frame, raw_frame, stream_in, flush=True)\n",
    "\n",
    "    container_out.close()\n",
    "    container_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_frame(self, c_out, s_out, image_out, rawframe_in, s_in, flush = False):\n",
    "\n",
    "    if np.shape(image_out)[2] == 3:\n",
    "        frame_out = av.VideoFrame.from_ndarray(image_out, format='bgr24')\n",
    "    else:\n",
    "        frame_out = av.VideoFrame.from_ndarray(image_out, format='bgra')\n",
    "\n",
    "    frame_out.time_base = rawframe_in.time_base\n",
    "    frame_out.pts = rawframe_in.pts\n",
    "\n",
    "    if flush:\n",
    "        for packet_out in s_out.encode():\n",
    "            c_out.mux(packet_out)\n",
    "    else:\n",
    "\n",
    "        for packet_out in s_out.encode(frame_out):\n",
    "            packet_out.stream = s_out\n",
    "            packet_out.time_base = rawframe_in.time_base\n",
    "            packet_out.pts = rawframe_in.pts\n",
    "            c_out.mux(packet_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "\n",
    "source.overlay_gaze_on_video = types.MethodType( overlay_gaze_on_video, source )\n",
    "\n",
    "source.overlay_gaze_on_frame = types.MethodType( overlay_gaze_on_frame, source )\n",
    "\n",
    "source.create_containers_and_streams = types.MethodType( create_containers_and_streams, source )\n",
    "\n",
    "source.import_gaze_from_exports = types.MethodType( import_gaze_from_exports, source )\n",
    "\n",
    "source.encode_frame = types.MethodType( encode_frame, source )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Working.: 100%|██████████| 564/564 [00:04<00:00, 136.23frames/s]\n"
     ]
    }
   ],
   "source": [
    "source.overlay_gaze_on_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b = source.create_containers_and_streams(False, 'gaze_overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streams: 2\n"
     ]
    }
   ],
   "source": [
    "# dfdfd\n",
    "\n",
    "# create_containers_and_streams(self, algorithm, visualize_as):\n",
    "\n",
    "algorithm = False\n",
    "visualize_as = 'gaze_overlay'\n",
    "\n",
    "container_in = av.open(source.file_path)\n",
    "average_fps = container_in.streams.video[0].average_rate\n",
    "height = container_in.streams.video[0].height\n",
    "width = container_in.streams.video[0].width\n",
    "\n",
    "##############################\n",
    "# prepare video out\n",
    "if visualize_as == 'gaze_overlay':\n",
    "    video_out_name = source.source_file_name + '_gaze-overlay.mp4'\n",
    "else:\n",
    "    video_out_name = source.source_file_name + '_' + algorithm + '_' + visualize_as + '.mp4'\n",
    "\n",
    "if os.path.isdir(source.video_out_path) is False:\n",
    "    os.makedirs(source.video_out_path)\n",
    "\n",
    "container_out = av.open(os.path.join(source.video_out_path, video_out_name), mode=\"w\", timeout=None)\n",
    "\n",
    "stream_out = container_out.add_stream(\"libx264\", framerate=average_fps)\n",
    "stream_out.options[\"crf\"] = \"20\"\n",
    "stream_out.pix_fmt = container_in.streams.video[0].pix_fmt\n",
    "stream_out.time_base = container_in.streams.video[0].time_base\n",
    "stream_out = source.set_stream_dimensions(stream_out, visualize_as, height, width)\n",
    "stream_out.codec_context.bit_rate = container_in.streams.video[0].codec_context.bit_rate\n",
    "\n",
    "\n",
    "if visualize_as == 'gaze_overlay':\n",
    "    overlay_stream = container_out.add_stream(\"libx264\", framerate=average_fps)\n",
    "    overlay_stream.options[\"crf\"] = \"20\"\n",
    "    overlay_stream.pix_fmt = container_in.streams.video[0].pix_fmt #'yuva444p10le'\n",
    "    overlay_stream.time_base = container_in.streams.video[0].time_base\n",
    "    overlay_stream = source.set_stream_dimensions(stream_out, visualize_as, height, width)\n",
    "\n",
    "print(f'Streams: {len(container_out.streams)}')\n",
    "# return container_in, container_out\n",
    "# def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3855958"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin = container_in.streams.video[0]\n",
    "sin.codec_context.bit_rate\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # container_in, container_out = self.create_containers_and_streams(algorithm=False,visualize_as='gaze_overlay')\n",
    "# self = source\n",
    "\n",
    "# stream_in = container_in.streams.video[0]\n",
    "\n",
    "# num_frames = stream_in.frames\n",
    "\n",
    "# # for raw_frame in container_in.decode(video=0):\n",
    "# for raw_frame in tqdm(container_in.decode(video=0), desc=\"Working.\", unit= 'frames',total = num_frames):\n",
    "\n",
    "#     current_bgr = raw_frame.to_ndarray(format='bgr24')\n",
    "#     current_bgr_processed = self.preprocess_frame(current_bgr)\n",
    "\n",
    "#     overlay_frame = self.draw_gaze_overlay(raw_frame.width, raw_frame.height, raw_frame.index)\n",
    "\n",
    "#     self.encode_frame(container_out, stream_out, current_bgr_processed, raw_frame, stream_in)\n",
    "#     self.encode_frame(container_out, overlay_stream, overlay_frame, raw_frame, stream_in)\n",
    "\n",
    "# self.encode_frame(container_out, stream_out, current_bgr_processed, raw_frame, stream_in)\n",
    "# self.encode_frame(container_out, overlay_stream, overlay_frame, raw_frame, stream_in)\n",
    "\n",
    "# container_out.close()\n",
    "# container_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = np.zeros((480,640,4), np.uint8)\n",
    "# np.shape(frame)[2] == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (retinal_flow_toolkit)",
   "language": "python",
   "name": "pycharm-87d68fc0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}